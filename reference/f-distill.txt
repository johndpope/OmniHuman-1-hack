License: arXiv.org perpetual non-exclusive license
arXiv:2502.15681v1 [cs.LG] 21 Feb 2025
One-step Diffusion Models with 
f
-Divergence Distribution Matching
Yilun Xu
NVIDIA yilunx@nvidia.com
Weili Nie
NVIDIA wnie@nvidia.com
Arash Vahdat
NVIDIA avahdat@nvidia.com
Abstract
Sampling from diffusion models involves a slow iterative process that hinders their practical deployment, especially for interactive applications. To accelerate generation speed, recent approaches distill a multi-step diffusion model into a single-step student generator via variational score distillation, which matches the distribution of samples generated by the student to the teacherâ€™s distribution. However, these approaches use the reverse Kullbackâ€“Leibler (KL) divergence for distribution matching which is known to be mode seeking. In this paper, we generalize the distribution matching approach using a novel 
f
-divergence minimization framework, termed 
f
-distill, that covers different divergences with different trade-offs in terms of mode coverage and training variance. We derive the gradient of the 
f
-divergence between the teacher and student distributions and show that it is expressed as the product of their score differences and a weighting function determined by their density ratio. This weighting function naturally emphasizes samples with higher density in the teacher distribution, when using a less mode-seeking divergence. We observe that the popular variational score distillation approach using the reverse-KL divergence is a special case within our framework. Empirically, we demonstrate that alternative 
f
-divergences, such as forward-KL and Jensen-Shannon divergences, outperform the current best variational score distillation methods across image generation tasks. In particular, when using Jensen-Shannon divergence, 
f
-distill achieves current state-of-the-art one-step generation performance on ImageNet64 and zero-shot text-to-image generation on MS-COCO. Project page: https://research.nvidia.com/labs/genair/f-distill/

1Introduction
Diffusion models [12, 58] are transforming generative modeling in visual domains, with impressive success in generating images [43, 44, 1], videos [13, 53], 3D objects [32, 75], motion [76, 74], etc. However, one of the key limitations of deploying diffusion models in real-world applications is their slow and computationally expensive sampling process that involves calling the denoising neural network iteratively.

Early works on accelerating diffusion models relied on better numerical solvers for solving the ordinary differential equations (ODEs) or stochastic differential equations (SDEs) that describe the sampling process of diffusion models [54, 15, 29, 17, 67]. However, these methods can only reduce the number of sampling steps to around tens of steps, due to the discretization error, accumulated with fewer steps.

More recently, distillation-based approaches aim at the ambitious goal of reducing the number of sampling steps to a single network call. These approaches can be generally grouped into two categories: 1) trajectory distillation [59, 55, 9, 23, 28] which distills the deterministic ODE mapping between noise and data intrinsic in a diffusion model to a one-step student, and 2) distribution matching approaches [72, 71, 79, 82] that ignore the deterministic mappings, and instead, matches the distribution of samples generated by a one-step student to the distribution imposed by a pre-trained teacher diffusion model. Among the two categories, the latter often performs better in practice as the deterministic mapping between noise and data is deemed complex and hard to learn. Naturally, the choice of divergence in distribution matching plays a key role as it dictates how the studentâ€™s distribution is matched against the teacherâ€™s. Existing works [72, 71] often use variational score distillation [64] that matches the distribution of the student and teacher by minimizing the reverse-KL divergence. However, this divergence is known to be mode-seeking [2] and can potentially ignore diverse modes learned by the diffusion model.

Refer to caption
Figure 1:The gradient update for the one-step student in 
f
-distill. The gradient is a product of the difference between the teacher score and fake score, and a weighting function determined by the chosen 
f
-divergence and density ratio. The density ratio is readily available from the discriminator in the auxiliary GAN objective.
In this work, we propose a novel generalization of the distribution matching distillation approach using the 
f
-divergence, termed 
f
-distill. The 
f
-divergence represents a large family of divergences including reverse-KL, forward-KL, Jensen-Shannon (JS), squared Hellinger, etc. These divergences come with different trade-offs on how they penalize the student for missing modes in the teacher distribution and how they can be estimated and optimized using Monte Carlo sampling. Within our framework, we evaluate various 
f
-divergences based on these properties and observe different tradeoff. For instance, forward-KL has a better mode coverage, but has a large gradient variance; JS demonstrates moderate mode-seeking and gradient saturation, particularly in early training stages, but exhibits low variance. Our analysis reveals that no single 
f
-divergence consistently outperforms others across all datasets. We observe divergences with better mode coverage tendencies generally perform better on the CIFAR-10 dataset. However, on large-scale challenging datasets like ImageNet-64 and text-to-image generation with Stable Diffusion (SD), divergences with lower variance achieve superior results.

Refer to caption
Figure 2:Score difference and the weighting function on a 2D example. 
h
 is the weighting function in forward-KL. Observe that the teacher and fake scores often diverge in lower-density regions (darker colors in the bottom left figure indicate larger score differences), where larger estimation errors occur. The weighting function downweights these regions (lighter colors in the bottom right figure) during gradient updates for 
f
-distill.
Our derivation of the 
f
-divergence distribution matching shows that the gradient of the objectives is the product of the difference in score between teacher and student (which also exists in prior works), and a weighting function that depends on density ratio and the chosen 
f
-divergence (new in this work), as illustrated in Fig. 1. The density ratio can be readily obtained from the discriminator in the commonly used auxiliary GAN objective. We show that the previous DMD approach is a special case of our approach that corresponds to a constant weighting. We discuss how the newly derived weighting coefficient influences the tradeoffs discussed above and propose normalization techniques for stabilizing divergences with higher gradient variance. As shown in Fig. 2, we observe that the weight coefficient for 
f
-divergences with less mode-seeking tendency will downweight the score difference in the areas where the teacher has low density. This is in line with the recent observation that score estimation in low-density regions can be inaccurate [18], and it allows our model to adaptively rely less on matching its score with the teacherâ€™s unreliable score on such regions.

Empirically, we validate the 
f
-distill framework on several image generation tasks. Quantitative results demonstrate that the less mode-seeking divergences in 
f
-distill consistently outperform previous best variational score distillation approaches. Notably, by minimizing the less mode-seeking and lower gradient variance Jensen-Shannon divergences, 
f
-distill achieves new state-of-the-art one-step generation performance on ImageNet-64 and zero-shot MS-COCO (using SD v1.5). Furthermore, our experiments confirm that the weighting function effectively assigns smaller weights to regions with larger score differences.

Contributions. (i) We propose a novel generalization of distribution matching distillation using 
f
-divergence, allowing flexibility in how the student distribution is matched against the teacherâ€™s. (ii) We discuss different trade-offs with different choices of 
f
-divergence in terms of mode seeking, gradient saturation and variance. (iii) We provide practical guidelines on reducing the variance of gradient and estimating different terms in the objective efficiently. (iv) We empirically show that our proposed 
f
-distill achieves the state-of-the-art FID score in one-step generation on the ImageNet-64 and zero-shot MS-COCO text-to-image benchmark.

2Background
2.1Diffusion models
The goal of 
f
-distill is to accelerate the generation of pre-trained (continuous-time) DMs [58, 12]. In this paper, we follow the popular EDM framework [17] for the notations and forward/backward processes. DMs perturb the clean data 
ğ±
0
âˆ¼
p
data
 in a fixed forward process using 
Ïƒ
2
â¢
(
t
)
-variance Gaussian noise, where 
ğ±
0
âˆˆ
â„
d
 and 
t
 denotes the time along the diffusion process. The resulting intermediate distribution is denoted as 
p
t
â¢
(
ğ±
t
)
 with 
ğ±
t
âˆˆ
â„
d
. For notation simplicity, we will use 
ğ±
 to replace 
ğ±
t
, unless stated otherwise, throughout the paper. For sufficiently large 
Ïƒ
max
, this distribution is almost identical to pure random Gaussian noise. DMs leverage this observation to sample the initial noise 
Ïµ
max
âˆ¼
ğ’©
â¢
(
ğŸ
,
Ïƒ
max
2
â¢
ğ‘°
)
, and then iteratively denoise the sample by solving the following backward ODE/SDE, which guarantees that if 
Ïƒ
â¢
(
0
)
=
0
, the final 
ğ±
 follows the data distribution 
p
data
:

d
â¢
ğ±
=
âˆ’
Ïƒ
Ë™
â¢
(
t
)
â¢
Ïƒ
â¢
(
t
)
â¢
âˆ‡
ğ±
log
â¡
p
t
â¢
(
ğ±
)
â¢
d
â¢
t
âŸ
Probability Flow ODE
âˆ’
Î²
â¢
(
t
)
â¢
Ïƒ
2
â¢
(
t
)
â¢
âˆ‡
ğ±
log
â¡
p
t
â¢
(
ğ±
)
â¢
d
â¢
t
+
2
â¢
Î²
â¢
(
t
)
â¢
Ïƒ
â¢
(
t
)
â¢
d
â¢
ğ
t
âŸ
Langevin Diffusion SDE
,
(1)
where 
ğ
t
 is a standard Wiener process and 
âˆ‡
ğ±
log
â¡
p
t
â¢
(
ğ±
)
 is the score function of the intermediate distribution 
p
t
â¢
(
ğ±
)
. The score function is learned by a neural network 
s
Ï•
â¢
(
ğ±
;
Ïƒ
â¢
(
t
)
)
 trained with the denoising score matching objective [62, 56]. In Equation 1, the first term is the Probability Flow ODE, which guides samples from high to low noise levels. The second term is a Langevin Diffusion SDE, which acts as an equilibrium sampler across different noise levels 
Ïƒ
â¢
(
t
)
, effectively refining the samples and correcting errors during the sampling process [17, 67]. This component can be scaled by the time-dependent parameter 
Î²
â¢
(
t
)
. Setting 
Î²
â¢
(
t
)
=
0
 leads to pure ODE-based synthesis. However, solving the diffusion ODE and SDE typically involves a considerable number of iterations (often tens or hundreds), posing a significant challenge to the practical deployment of diffusion models. Although different kinds of accelerated samplers for diffusion ODE [54, 29, 17] and SDE [15, 17, 67] have been proposed, they usually still require 
>
20
 sampling steps in practice to produce decent samples.

2.2Variational score distillation
A recent line of works [72, 71] aim to distill the teacher diffusion models 
s
Ï•
 into a single step generator 
G
Î¸
, through variational score distillation (VSD), which is originally introduced for test-time optimization of 3D objects [64]. The goal is to enable a student model 
G
Î¸
 to directly map the noise 
ğ³
 from the prior distribution 
p
â¢
(
ğ³
)
=
ğ’©
â¢
(
ğ³
;
ğŸ
,
ğ‘°
)
 to the clean sample 
ğ±
0
 at 
Ïƒ
=
0
 using 
ğ±
0
=
G
Î¸
â¢
(
ğ³
)
, effectively bypassing the iterative sampling process. Let 
p
Ï•
 denote the distribution obtained by plugging in pre-trained diffusion models 
s
Ï•
â¢
(
ğ±
;
Ïƒ
â¢
(
t
)
)
 in Equation 1, and let 
q
Î¸
 denote the output distribution by the one-step generator 
G
Î¸
 (in the following text, we drop the subscript in 
p
Ï•
 and 
q
Î¸
 for notation simplicity). Then, the gradient update for the generator can be formulated as follows:

ğ”¼
t
,
ğ³
,
Ïµ
â¢
[
(
s
Ï•
â¢
(
ğ±
;
Ïƒ
â¢
(
t
)
)
âˆ’
âˆ‡
ğ±
log
â¡
q
Î¸
â¢
(
ğ±
;
Ïƒ
â¢
(
t
)
)
)
â¢
âˆ‡
Î¸
G
Î¸
â¢
(
ğ³
)
]
(2)
where 
ğ±
=
G
Î¸
â¢
(
ğ³
)
+
Ïƒ
â¢
(
t
)
â¢
Ïµ
 and 
Ïµ
âˆ¼
ğ’©
â¢
(
ğŸ
,
ğ‘°
)
. Intuitively, the gradient encourages the generator to produce samples that lie within high-density regions of the data distribution. This is achieved through the teacher score term, 
s
Ï•
â¢
(
ğ±
;
Ïƒ
â¢
(
t
)
)
, which guides the generated samples towards areas where the teacher model assigns high probability. To prevent mode collapse, the gradient also incorporates a term that discourages the generator from simply concentrating on a single high-density point in the teacherâ€™s distribution. This is done by subtracting the score of the student distribution, 
âˆ‡
ğ±
log
â¡
q
Î¸
â¢
(
ğ±
;
Ïƒ
â¢
(
t
)
)
. The gradient update is shown to perform distribution matching by minimizing the reverse-KL divergence between the teacher and student distributions [39, 72].

To estimate the score of the student distribution, previous works [64, 72] have employed another fake score network 
s
Ïˆ
â¢
(
ğ±
,
Ïƒ
â¢
(
t
)
)
 to approximate 
âˆ‡
ğ±
log
â¡
q
Î¸
â¢
(
ğ±
;
Ïƒ
â¢
(
t
)
)
. The fake score network 
s
Ïˆ
â¢
(
ğ±
,
Ïƒ
â¢
(
t
)
)
 is dynamically updated with the standard denoising score matching loss, where the â€œcleanâ€ samples come from the generator 
G
Î¸
 during training. Thus, the VSD training alternates between the generator update and the fake score update, with a two time-scale update rule for stabilized training [71]. Additionally, to further close the gap between the one-step generator and the multi-step teacher diffusion model, a GAN loss is applied to the VSD training pipeline [71], where a lightweight GAN classifier takes as input the middle features from the fake score network.

2.3
f
-divergence
In probability theory, an 
f
-divergence [41] quantifies the difference between two probability density functions, 
p
 and 
q
. Specifically, when 
p
 is absolutely continuous with respect to 
q
, the 
f
-divergence is defined as:

D
f
(
p
|
|
q
)
=
âˆ«
q
(
ğ±
)
f
(
p
â¢
(
ğ±
)
q
â¢
(
ğ±
)
)
d
ğ±
where 
f
 is a convex function on 
(
0
,
+
âˆ
)
 satisfying 
f
â¢
(
1
)
=
0
. This divergence satisfies several important properties, including non-negativity and the data processing inequality. Many commonly used divergences can be expressed as special cases of the 
f
-divergence by choosing an appropriate function 
f
. These include the forward-KL divergence, reverse-KL divergence, Hellinger distance, and Jensen-Shannon (JS) divergence, as shown in Table 1. In generative learning, 
f
-divergence has been widely applied to popular generative models, such as GANs [37], VAEs [63], energy-based models [73] and diffusion models [60].

3Method: general 
f
-divergence minimization
f
â¢
(
r
)
h
â¢
(
r
)
Mode-seeking?	Saturation?	Variance
reverse-KL	
âˆ’
log
â¡
r
1
Yes	No	-
softened RKL	
(
r
+
1
)
â¢
log
â¡
(
1
2
+
1
2
â¢
r
)
1
r
+
1
Yes	No	Low
Jensen-Shannon	
r
â¢
log
â¡
r
âˆ’
(
r
+
1
)
â¢
log
â¡
r
+
1
2
r
r
+
1
Medium	Yes	Low
squared Hellinger	
1
âˆ’
r
1
4
â¢
r
1
2
Medium	Yes	Low
forward-KL	
r
â¢
log
â¡
r
r
No	No	High
Jeffreys	
(
r
âˆ’
1
)
â¢
log
â¡
(
r
)
r
+
1
No	No	High
Table 1:Comparison of different 
f
-divergences as a function of the likelihood ratio 
r
:=
p
â¢
(
ğ±
)
/
q
â¢
(
ğ±
)
In this section, we introduce a general distillation framework, termed 
f
-distill, based on minimizing the 
f
-divergence between the teacher and student distributions. Since the student distribution 
q
 is the push-forward measure induced by the one-step generator 
G
Î¸
, it implicitly depends on the generatorâ€™s parameters 
Î¸
. Due to this implicit dependency, directly calculating the gradient of 
f
-divergence, 
D
f
(
p
|
|
q
)
, w.r.t 
Î¸
 presents a challenge. However, the following theorem establishes the analytical expression for this gradient, revealing that it can be formulated as a weighted version of the gradient employed in variational score distillation. Notably, these weights are determined by the density ratio of the generated samples. We state the theorem more generally by providing the gradient for 
p
t
 and 
q
t
, where 
p
t
 is the perturbed distribution through the diffusion forward process for the teacherâ€™s distribution 
p
, i.e., 
p
t
=
p
0
âˆ—
ğ’©
â¢
(
ğŸ
,
Ïƒ
2
â¢
(
t
)
â¢
ğ‘°
)
 (same for the student distribution 
q
).

Theorem 1.
Let 
p
 be the teacherâ€™s generative distribution, and let 
q
 be a distribution induced by transforming a prior distribution 
p
â¢
(
ğ³
)
 through the differentiable mapping 
G
Î¸
. Assuming 
f
 is twice continuously differentiable, then the gradient of 
f
-divergence between the two intermediate distribution 
p
t
 and 
q
t
 w.r.t 
Î¸
 is:

âˆ‡
Î¸
D
f
(
p
t
|
|
q
t
)
=
ğ”¼
ğ³
,
Ïµ
âˆ’
[
f
â€²â€²
(
p
t
â¢
(
ğ±
)
q
t
â¢
(
ğ±
)
)
(
p
t
â¢
(
ğ±
)
q
t
â¢
(
ğ±
)
)
2
(
âˆ‡
ğ±
log
â¡
p
t
â¢
(
ğ±
)
âŸ
teacher score
âˆ’
âˆ‡
ğ±
log
â¡
q
t
â¢
(
ğ±
)
âŸ
fake score
)
âˆ‡
Î¸
G
Î¸
(
ğ³
)
]
(3)
